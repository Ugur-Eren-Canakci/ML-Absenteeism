{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9cb001d-fb71-4fb7-95fb-28bd2ef72f8d",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5796f403-bddd-4ca0-8dc2-de21e756423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler # To be inherited by CustomScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac1b86-5ff4-465b-bfdc-33a8073fe97d",
   "metadata": {},
   "source": [
    "### Import the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de25939-7d38-48d9-bd67-84a283b6b8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absence Reason 1</th>\n",
       "      <th>Absence Reason 2</th>\n",
       "      <th>Absence Reason 3</th>\n",
       "      <th>Absence Reason 4</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day of the Week</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Distance to Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Daily Work Load Average</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Absenteeism Time in Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Absence Reason 1  Absence Reason 2  Absence Reason 3  Absence Reason 4  \\\n",
       "0                 0                 0                 0                 1   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 1   \n",
       "3                 1                 0                 0                 0   \n",
       "4                 0                 0                 0                 1   \n",
       "\n",
       "   Month  Day of the Week  Transportation Expense  Distance to Work  Age  \\\n",
       "0      7                1                     289                36   33   \n",
       "1      7                1                     118                13   50   \n",
       "2      7                2                     179                51   38   \n",
       "3      7                3                     279                 5   39   \n",
       "4      7                3                     289                36   33   \n",
       "\n",
       "   Daily Work Load Average  Body Mass Index  Education  Children  Pets  \\\n",
       "0                  239.554               30          0         2     1   \n",
       "1                  239.554               31          0         1     0   \n",
       "2                  239.554               31          0         0     0   \n",
       "3                  239.554               24          0         2     0   \n",
       "4                  239.554               30          0         2     1   \n",
       "\n",
       "   Absenteeism Time in Hours  \n",
       "0                          4  \n",
       "1                          0  \n",
       "2                          2  \n",
       "3                          4  \n",
       "4                          2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed = pd.read_csv(\"Absenteeism_processed_data.csv\")\n",
    "df = data_preprocessed.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1065f4b-23e3-49ed-916d-90d363ed5655",
   "metadata": {},
   "source": [
    "We will classify people into \"moderately absent\" and \"excessively absent\".\n",
    "\n",
    "Total absent hours will be the grouped into two, and the boundary of these two groups will be the \"median\" value of absenteeism time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d293681d-f8a5-4240-9ae0-f8cd418ce4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Absenteeism Time in Hours\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202b6501-84cd-4a37-93d2-74cf597418a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Series name: Absenteeism Time in Hours\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "700 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 5.6 KB\n"
     ]
    }
   ],
   "source": [
    "df[\"Absenteeism Time in Hours\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c558de2c-c863-46f8-8c3c-8cff11dabdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absence Reason 1</th>\n",
       "      <th>Absence Reason 2</th>\n",
       "      <th>Absence Reason 3</th>\n",
       "      <th>Absence Reason 4</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day of the Week</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Distance to Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Daily Work Load Average</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Absence Reason 1  Absence Reason 2  Absence Reason 3  Absence Reason 4  \\\n",
       "0                 0                 0                 0                 1   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 1   \n",
       "3                 1                 0                 0                 0   \n",
       "4                 0                 0                 0                 1   \n",
       "\n",
       "   Month  Day of the Week  Transportation Expense  Distance to Work  Age  \\\n",
       "0      7                1                     289                36   33   \n",
       "1      7                1                     118                13   50   \n",
       "2      7                2                     179                51   38   \n",
       "3      7                3                     279                 5   39   \n",
       "4      7                3                     289                36   33   \n",
       "\n",
       "   Daily Work Load Average  Body Mass Index  Education  Children  Pets  Target  \n",
       "0                  239.554               30          0         2     1       1  \n",
       "1                  239.554               31          0         1     0       0  \n",
       "2                  239.554               31          0         0     0       0  \n",
       "3                  239.554               24          0         2     0       1  \n",
       "4                  239.554               30          0         2     1       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    if df.loc[i,\"Absenteeism Time in Hours\"] > int(df[\"Absenteeism Time in Hours\"].median()):\n",
    "        targets.append(1)\n",
    "    else:\n",
    "        targets.append(0)\n",
    "\n",
    "df[\"Target\"] = targets\n",
    "df = df.drop([\"Absenteeism Time in Hours\"],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc006aae-1590-47e2-8728-07a34942c212",
   "metadata": {},
   "source": [
    "We will drop month, daily work load average and distance to work. These features have weights very close to 1 towards the likelihood of having excess absence. This decision was made after a model was fitted while keeping these features in.\n",
    "\n",
    "This action is equivalent to \"not rejecting that their effect on absence is zero\", i.e. throwing out independent variables whose weights' p-values are too large under the null hypothesis. This means that under the assumption that they don't affect absence times, current sample of absences is possible to encounter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1126c26-8fd3-4fb7-ab29-07828d35db62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absence Reason 1</th>\n",
       "      <th>Absence Reason 2</th>\n",
       "      <th>Absence Reason 3</th>\n",
       "      <th>Absence Reason 4</th>\n",
       "      <th>Day of the Week</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Age</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>279</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>289</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>330</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>235</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>291</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Absence Reason 1  Absence Reason 2  Absence Reason 3  Absence Reason 4  \\\n",
       "0                   0                 0                 0                 1   \n",
       "1                   0                 0                 0                 0   \n",
       "2                   0                 0                 0                 1   \n",
       "3                   1                 0                 0                 0   \n",
       "4                   0                 0                 0                 1   \n",
       "..                ...               ...               ...               ...   \n",
       "695                 1                 0                 0                 0   \n",
       "696                 1                 0                 0                 0   \n",
       "697                 1                 0                 0                 0   \n",
       "698                 0                 0                 0                 1   \n",
       "699                 0                 0                 0                 1   \n",
       "\n",
       "     Day of the Week  Transportation Expense  Age  Body Mass Index  Education  \\\n",
       "0                  1                     289   33               30          0   \n",
       "1                  1                     118   50               31          0   \n",
       "2                  2                     179   38               31          0   \n",
       "3                  3                     279   39               24          0   \n",
       "4                  3                     289   33               30          0   \n",
       "..               ...                     ...  ...              ...        ...   \n",
       "695                2                     179   40               22          1   \n",
       "696                2                     225   28               24          0   \n",
       "697                3                     330   28               25          1   \n",
       "698                3                     235   32               25          1   \n",
       "699                3                     291   40               25          0   \n",
       "\n",
       "     Children  Pets  Target  \n",
       "0           2     1       1  \n",
       "1           1     0       0  \n",
       "2           0     0       0  \n",
       "3           2     0       1  \n",
       "4           2     1       0  \n",
       "..        ...   ...     ...  \n",
       "695         2     0       1  \n",
       "696         1     2       0  \n",
       "697         0     0       1  \n",
       "698         0     0       0  \n",
       "699         1     1       0  \n",
       "\n",
       "[700 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop([\"Month\", \"Daily Work Load Average\", \"Distance to Work\"],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3b841-cb8b-48fd-a815-901b26b35a39",
   "metadata": {},
   "source": [
    "### Separate inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "835330e3-e87e-48c5-9e04-442cfa2236c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_nonscaled = df.iloc[:,:-1]\n",
    "target_data = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa6dda6-22c3-46d1-92bd-d7cffd4151c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absence Reason 1</th>\n",
       "      <th>Absence Reason 2</th>\n",
       "      <th>Absence Reason 3</th>\n",
       "      <th>Absence Reason 4</th>\n",
       "      <th>Day of the Week</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Age</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>279</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>289</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Absence Reason 1  Absence Reason 2  Absence Reason 3  Absence Reason 4  \\\n",
       "0                 0                 0                 0                 1   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 1   \n",
       "3                 1                 0                 0                 0   \n",
       "4                 0                 0                 0                 1   \n",
       "\n",
       "   Day of the Week  Transportation Expense  Age  Body Mass Index  Education  \\\n",
       "0                1                     289   33               30          0   \n",
       "1                1                     118   50               31          0   \n",
       "2                2                     179   38               31          0   \n",
       "3                3                     279   39               24          0   \n",
       "4                3                     289   33               30          0   \n",
       "\n",
       "   Children  Pets  \n",
       "0         2     1  \n",
       "1         1     0  \n",
       "2         0     0  \n",
       "3         2     0  \n",
       "4         2     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_nonscaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb4c41-a8b7-48f1-ab18-6c18d06ffa6f",
   "metadata": {},
   "source": [
    "### Standardize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2eb48f7-9f36-416b-a830-f733a496f49f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on StandardScaler in module sklearn.preprocessing._data object:\n",
      "\n",
      "class StandardScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  StandardScaler(*, copy=True, with_mean=True, with_std=True)\n",
      " |  \n",
      " |  Standardize features by removing the mean and scaling to unit variance.\n",
      " |  \n",
      " |  The standard score of a sample `x` is calculated as:\n",
      " |  \n",
      " |      z = (x - u) / s\n",
      " |  \n",
      " |  where `u` is the mean of the training samples or zero if `with_mean=False`,\n",
      " |  and `s` is the standard deviation of the training samples or one if\n",
      " |  `with_std=False`.\n",
      " |  \n",
      " |  Centering and scaling happen independently on each feature by computing\n",
      " |  the relevant statistics on the samples in the training set. Mean and\n",
      " |  standard deviation are then stored to be used on later data using\n",
      " |  :meth:`transform`.\n",
      " |  \n",
      " |  Standardization of a dataset is a common requirement for many\n",
      " |  machine learning estimators: they might behave badly if the\n",
      " |  individual features do not more or less look like standard normally\n",
      " |  distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
      " |  \n",
      " |  For instance many elements used in the objective function of\n",
      " |  a learning algorithm (such as the RBF kernel of Support Vector\n",
      " |  Machines or the L1 and L2 regularizers of linear models) assume that\n",
      " |  all features are centered around 0 and have variance in the same\n",
      " |  order. If a feature has a variance that is orders of magnitude larger\n",
      " |  than others, it might dominate the objective function and make the\n",
      " |  estimator unable to learn from other features correctly as expected.\n",
      " |  \n",
      " |  `StandardScaler` is sensitive to outliers, and the features may scale\n",
      " |  differently from each other in the presence of outliers. For an example\n",
      " |  visualization, refer to :ref:`Compare StandardScaler with other scalers\n",
      " |  <plot_all_scaling_standard_scaler_section>`.\n",
      " |  \n",
      " |  This scaler can also be applied to sparse CSR or CSC matrices by passing\n",
      " |  `with_mean=False` to avoid breaking the sparsity structure of the data.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  copy : bool, default=True\n",
      " |      If False, try to avoid a copy and do inplace scaling instead.\n",
      " |      This is not guaranteed to always work inplace; e.g. if the data is\n",
      " |      not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
      " |      returned.\n",
      " |  \n",
      " |  with_mean : bool, default=True\n",
      " |      If True, center the data before scaling.\n",
      " |      This does not work (and will raise an exception) when attempted on\n",
      " |      sparse matrices, because centering them entails building a dense\n",
      " |      matrix which in common use cases is likely to be too large to fit in\n",
      " |      memory.\n",
      " |  \n",
      " |  with_std : bool, default=True\n",
      " |      If True, scale the data to unit variance (or equivalently,\n",
      " |      unit standard deviation).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  scale_ : ndarray of shape (n_features,) or None\n",
      " |      Per feature relative scaling of the data to achieve zero mean and unit\n",
      " |      variance. Generally this is calculated using `np.sqrt(var_)`. If a\n",
      " |      variance is zero, we can't achieve unit variance, and the data is left\n",
      " |      as-is, giving a scaling factor of 1. `scale_` is equal to `None`\n",
      " |      when `with_std=False`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_*\n",
      " |  \n",
      " |  mean_ : ndarray of shape (n_features,) or None\n",
      " |      The mean value for each feature in the training set.\n",
      " |      Equal to ``None`` when ``with_mean=False`` and ``with_std=False``.\n",
      " |  \n",
      " |  var_ : ndarray of shape (n_features,) or None\n",
      " |      The variance for each feature in the training set. Used to compute\n",
      " |      `scale_`. Equal to ``None`` when ``with_mean=False`` and\n",
      " |      ``with_std=False``.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_samples_seen_ : int or ndarray of shape (n_features,)\n",
      " |      The number of samples processed by the estimator for each feature.\n",
      " |      If there are no missing samples, the ``n_samples_seen`` will be an\n",
      " |      integer, otherwise it will be an array of dtype int. If\n",
      " |      `sample_weights` are used it will be a float (if no missing data)\n",
      " |      or an array of dtype float that sums the weights seen so far.\n",
      " |      Will be reset on new calls to fit, but increments across\n",
      " |      ``partial_fit`` calls.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  scale : Equivalent function without the estimator API.\n",
      " |  \n",
      " |  :class:`~sklearn.decomposition.PCA` : Further removes the linear\n",
      " |      correlation across features with 'whiten=True'.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      " |  transform.\n",
      " |  \n",
      " |  We use a biased estimator for the standard deviation, equivalent to\n",
      " |  `numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to\n",
      " |  affect model performance.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
      " |  >>> scaler = StandardScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  StandardScaler()\n",
      " |  >>> print(scaler.mean_)\n",
      " |  [0.5 0.5]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[-1. -1.]\n",
      " |   [-1. -1.]\n",
      " |   [ 1.  1.]\n",
      " |   [ 1.  1.]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[3. 3.]]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StandardScaler\n",
      " |      sklearn.base.OneToOneFeatureMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, copy=True, with_mean=True, with_std=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None, sample_weight=None)\n",
      " |      Compute the mean and std to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample.\n",
      " |      \n",
      " |          .. versionadded:: 0.24\n",
      " |             parameter *sample_weight* support to StandardScaler.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |  \n",
      " |  inverse_transform(self, X, copy=None)\n",
      " |      Scale back the data to the original representation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, default=None\n",
      " |          Copy the input X or not.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None, sample_weight=None)\n",
      " |      Online computation of mean and std on X for later scaling.\n",
      " |      \n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when :meth:`fit` is not feasible due to very large number of\n",
      " |      `n_samples` or because X is read from a continuous stream.\n",
      " |      \n",
      " |      The algorithm for incremental mean and std is given in Equation 1.5a,b\n",
      " |      in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. \"Algorithms\n",
      " |      for computing the sample variance: Analysis and recommendations.\"\n",
      " |      The American Statistician 37.3 (1983): 242-247:\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample.\n",
      " |      \n",
      " |          .. versionadded:: 0.24\n",
      " |             parameter *sample_weight* support to StandardScaler.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.preprocessing._data.StandardScaler, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_inverse_transform_request(self: sklearn.preprocessing._data.StandardScaler, *, copy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``inverse_transform`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``inverse_transform`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``inverse_transform``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``copy`` parameter in ``inverse_transform``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_partial_fit_request(self: sklearn.preprocessing._data.StandardScaler, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``partial_fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_transform_request(self: sklearn.preprocessing._data.StandardScaler, *, copy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler\n",
      " |      Request metadata passed to the ``transform`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``transform`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``transform``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``copy`` parameter in ``transform``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  transform(self, X, copy=None)\n",
      " |      Perform standardization by centering and scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix of shape (n_samples, n_features)\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, default=None\n",
      " |          Copy the input X or not.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      " |  \n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Input features.\n",
      " |      \n",
      " |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      " |            used as feature names in. If `feature_names_in_` is not defined,\n",
      " |            then the following input feature names are generated:\n",
      " |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      " |          - If `input_features` is an array-like, then `input_features` must\n",
      " |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Same as input features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      " |      and returns a transformed version of `X`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input samples.\n",
      " |      \n",
      " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      " |          Target values (None for unsupervised transformations).\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |      \n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |      \n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `\"polars\"`: Polars output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |      \n",
      " |          .. versionadded:: 1.4\n",
      " |              `\"polars\"` option was added.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f4cdeb9-6a21-49ce-870e-aff287193607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from the course resources\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomScaler(BaseEstimator,TransformerMixin): \n",
    "    \n",
    "    # init or what information we need to declare a CustomScaler object\n",
    "    # and what is calculated/declared as we do\n",
    "    \n",
    "    def __init__(self,columns,copy=True,with_mean=True,with_std=True):\n",
    "        \n",
    "        # scaler is nothing but a Standard Scaler object\n",
    "        self.scaler = StandardScaler() # here, all true arguments had been put in as arguments for standardscaler, and that caused initiation to fail.\n",
    "        # so, I deleted the given arguments.\n",
    "        # with some columns 'twist'\n",
    "        self.columns = columns\n",
    "        self.mean_ = None\n",
    "        self.var_ = None\n",
    "        \n",
    "    \n",
    "    # the fit method, which, again based on StandardScale\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[self.columns], y)\n",
    "        self.mean_ = np.mean(X[self.columns])\n",
    "        self.var_ = np.var(X[self.columns])\n",
    "        return self\n",
    "    \n",
    "    # the transform method which does the actual scaling\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        \n",
    "        # record the initial order of the columns\n",
    "        init_col_order = X.columns\n",
    "        \n",
    "        # scale all features that you chose when creating the instance of the class\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)\n",
    "        \n",
    "        # declare a variable containing all information that was not scaled\n",
    "        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]\n",
    "        \n",
    "        # return a data frame which contains all scaled features and all 'not scaled' features\n",
    "        # use the original order (that you recorded in the beginning)\n",
    "        return pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67eb38b0-a62c-45d3-bc9d-b1ee67c3c917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Absence Reason 1', 'Absence Reason 2', 'Absence Reason 3',\n",
       "       'Absence Reason 4', 'Day of the Week', 'Transportation Expense',\n",
       "       'Age', 'Body Mass Index', 'Education', 'Children', 'Pets'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what are all columns that we've got\n",
    "input_data_nonscaled.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38fe60e5-cfc9-474e-bfd0-44c3eff99b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Day of the Week',\n",
       " 'Transportation Expense',\n",
       " 'Age',\n",
       " 'Body Mass Index',\n",
       " 'Children',\n",
       " 'Pets']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_omit = ['Absence Reason 1', 'Absence Reason 2', 'Absence Reason 3',\n",
    "       'Absence Reason 4', 'Education']\n",
    "columns_to_scale = [x for x in input_data_nonscaled.columns.values if x not in columns_to_omit]\n",
    "columns_to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89aae50e-d27d-447c-ad4c-ffba79d66a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ugur_\\anaconda3\\envs\\tf_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3785: FutureWarning: The behavior of DataFrame.var with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return var(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absence Reason 1</th>\n",
       "      <th>Absence Reason 2</th>\n",
       "      <th>Absence Reason 3</th>\n",
       "      <th>Absence Reason 4</th>\n",
       "      <th>Day of the Week</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Age</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.683704</td>\n",
       "      <td>1.005844</td>\n",
       "      <td>-0.536062</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.268487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.683704</td>\n",
       "      <td>-1.574681</td>\n",
       "      <td>2.130803</td>\n",
       "      <td>1.002633</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007725</td>\n",
       "      <td>-0.654143</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>1.002633</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.919030</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.668253</td>\n",
       "      <td>0.854936</td>\n",
       "      <td>0.405184</td>\n",
       "      <td>-0.643782</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.668253</td>\n",
       "      <td>1.005844</td>\n",
       "      <td>-0.536062</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.268487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007725</td>\n",
       "      <td>-0.654143</td>\n",
       "      <td>0.562059</td>\n",
       "      <td>-1.114186</td>\n",
       "      <td>1</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007725</td>\n",
       "      <td>0.040034</td>\n",
       "      <td>-1.320435</td>\n",
       "      <td>-0.643782</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>1.126663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.668253</td>\n",
       "      <td>1.624567</td>\n",
       "      <td>-1.320435</td>\n",
       "      <td>-0.408580</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.919030</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.668253</td>\n",
       "      <td>0.190942</td>\n",
       "      <td>-0.692937</td>\n",
       "      <td>-0.408580</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.919030</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.668253</td>\n",
       "      <td>1.036026</td>\n",
       "      <td>0.562059</td>\n",
       "      <td>-0.408580</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>0.268487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Absence Reason 1  Absence Reason 2  Absence Reason 3  Absence Reason 4  \\\n",
       "0                   0                 0                 0                 1   \n",
       "1                   0                 0                 0                 0   \n",
       "2                   0                 0                 0                 1   \n",
       "3                   1                 0                 0                 0   \n",
       "4                   0                 0                 0                 1   \n",
       "..                ...               ...               ...               ...   \n",
       "695                 1                 0                 0                 0   \n",
       "696                 1                 0                 0                 0   \n",
       "697                 1                 0                 0                 0   \n",
       "698                 0                 0                 0                 1   \n",
       "699                 0                 0                 0                 1   \n",
       "\n",
       "     Day of the Week  Transportation Expense       Age  Body Mass Index  \\\n",
       "0          -0.683704                1.005844 -0.536062         0.767431   \n",
       "1          -0.683704               -1.574681  2.130803         1.002633   \n",
       "2          -0.007725               -0.654143  0.248310         1.002633   \n",
       "3           0.668253                0.854936  0.405184        -0.643782   \n",
       "4           0.668253                1.005844 -0.536062         0.767431   \n",
       "..               ...                     ...       ...              ...   \n",
       "695        -0.007725               -0.654143  0.562059        -1.114186   \n",
       "696        -0.007725                0.040034 -1.320435        -0.643782   \n",
       "697         0.668253                1.624567 -1.320435        -0.408580   \n",
       "698         0.668253                0.190942 -0.692937        -0.408580   \n",
       "699         0.668253                1.036026  0.562059        -0.408580   \n",
       "\n",
       "     Education  Children      Pets  \n",
       "0            0  0.880469  0.268487  \n",
       "1            0 -0.019280 -0.589690  \n",
       "2            0 -0.919030 -0.589690  \n",
       "3            0  0.880469 -0.589690  \n",
       "4            0  0.880469  0.268487  \n",
       "..         ...       ...       ...  \n",
       "695          1  0.880469 -0.589690  \n",
       "696          0 -0.019280  1.126663  \n",
       "697          1 -0.919030 -0.589690  \n",
       "698          1 -0.919030 -0.589690  \n",
       "699          0 -0.019280  0.268487  \n",
       "\n",
       "[700 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absenteeism_scaler = CustomScaler(columns=columns_to_scale)\n",
    "absenteeism_scaler.fit(input_data_nonscaled)\n",
    "input_data_scaled = absenteeism_scaler.transform(input_data_nonscaled)\n",
    "input_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "710dce62-3f4a-43a5-921e-9afdd4597f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1becd11d-1922-4ff6-b52e-dc1995eab266",
   "metadata": {},
   "source": [
    "### Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce2a67db-f872-4024-b725-48b99a9325bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
      "    Split arrays or matrices into random train and test subsets.\n",
      "    \n",
      "    Quick utility that wraps input validation,\n",
      "    ``next(ShuffleSplit().split(X, y))``, and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data into a\n",
      "    one-liner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "        Read more in the :ref:`User Guide <stratification>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd3d02b3-89fb-47ca-8cae-a311618ea2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input_data_scaled,target_data, train_size = 0.83, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af216de8-e905-4b2c-8731-bf04efb106a9",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16fc75ef-e97a-4bdb-8183-6b63271e3fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'deprecated',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression()\n",
    "reg.fit(x_train,y_train)\n",
    "reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e17a95a-e828-4d63-aefa-28e4977d3732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7676419965576592"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3148ee82-041a-455c-ae34-1e2c90993488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7aac1df-79ed-47b3-add5-3b5b7be73156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80927939, 0.19072061],\n",
       "       [0.88276698, 0.11723302],\n",
       "       [0.74615201, 0.25384799],\n",
       "       [0.51582683, 0.48417317],\n",
       "       [0.50147608, 0.49852392],\n",
       "       [0.08524432, 0.91475568],\n",
       "       [0.59247801, 0.40752199],\n",
       "       [0.3734374 , 0.6265626 ],\n",
       "       [0.78314629, 0.21685371],\n",
       "       [0.70382213, 0.29617787],\n",
       "       [0.88276698, 0.11723302],\n",
       "       [0.72158449, 0.27841551],\n",
       "       [0.27062429, 0.72937571],\n",
       "       [0.54889554, 0.45110446],\n",
       "       [0.74158084, 0.25841916],\n",
       "       [0.40950001, 0.59049999],\n",
       "       [0.91755431, 0.08244569],\n",
       "       [0.25266512, 0.74733488],\n",
       "       [0.88276698, 0.11723302],\n",
       "       [0.59937804, 0.40062196],\n",
       "       [0.64554948, 0.35445052],\n",
       "       [0.77946225, 0.22053775],\n",
       "       [0.7154246 , 0.2845754 ],\n",
       "       [0.69423878, 0.30576122],\n",
       "       [0.87055492, 0.12944508],\n",
       "       [0.21074517, 0.78925483],\n",
       "       [0.59937804, 0.40062196],\n",
       "       [0.59022407, 0.40977593],\n",
       "       [0.77946225, 0.22053775],\n",
       "       [0.59937804, 0.40062196],\n",
       "       [0.88207109, 0.11792891],\n",
       "       [0.86759589, 0.13240411],\n",
       "       [0.40487936, 0.59512064],\n",
       "       [0.48289733, 0.51710267],\n",
       "       [0.76611891, 0.23388109],\n",
       "       [0.28704757, 0.71295243],\n",
       "       [0.76611891, 0.23388109],\n",
       "       [0.85164277, 0.14835723],\n",
       "       [0.12863715, 0.87136285],\n",
       "       [0.79924213, 0.20075787],\n",
       "       [0.40950001, 0.59049999],\n",
       "       [0.75587804, 0.24412196],\n",
       "       [0.5029487 , 0.4970513 ],\n",
       "       [0.8160189 , 0.1839811 ],\n",
       "       [0.77946225, 0.22053775],\n",
       "       [0.25614879, 0.74385121],\n",
       "       [0.20813814, 0.79186186],\n",
       "       [0.12097559, 0.87902441],\n",
       "       [0.6877357 , 0.3122643 ],\n",
       "       [0.83506083, 0.16493917],\n",
       "       [0.77946225, 0.22053775],\n",
       "       [0.7154246 , 0.2845754 ],\n",
       "       [0.56722816, 0.43277184],\n",
       "       [0.0535092 , 0.9464908 ],\n",
       "       [0.85164277, 0.14835723],\n",
       "       [0.70382213, 0.29617787],\n",
       "       [0.03319075, 0.96680925],\n",
       "       [0.7154246 , 0.2845754 ],\n",
       "       [0.12622724, 0.87377276],\n",
       "       [0.76324919, 0.23675081],\n",
       "       [0.48819031, 0.51180969],\n",
       "       [0.85164277, 0.14835723],\n",
       "       [0.46814651, 0.53185349],\n",
       "       [0.3734374 , 0.6265626 ],\n",
       "       [0.88276698, 0.11723302],\n",
       "       [0.62180464, 0.37819536],\n",
       "       [0.29780998, 0.70219002],\n",
       "       [0.93437621, 0.06562379],\n",
       "       [0.6877357 , 0.3122643 ],\n",
       "       [0.51255659, 0.48744341],\n",
       "       [0.70382213, 0.29617787],\n",
       "       [0.75587804, 0.24412196],\n",
       "       [0.23334325, 0.76665675],\n",
       "       [0.7154246 , 0.2845754 ],\n",
       "       [0.88474959, 0.11525041],\n",
       "       [0.34409004, 0.65590996],\n",
       "       [0.56722816, 0.43277184],\n",
       "       [0.75587804, 0.24412196],\n",
       "       [0.76611891, 0.23388109],\n",
       "       [0.59734455, 0.40265545],\n",
       "       [0.08524432, 0.91475568],\n",
       "       [0.10409118, 0.89590882],\n",
       "       [0.85164277, 0.14835723],\n",
       "       [0.80136677, 0.19863323],\n",
       "       [0.86759589, 0.13240411],\n",
       "       [0.33289113, 0.66710887],\n",
       "       [0.80136677, 0.19863323],\n",
       "       [0.12740789, 0.87259211],\n",
       "       [0.24455794, 0.75544206],\n",
       "       [0.7154246 , 0.2845754 ],\n",
       "       [0.81384097, 0.18615903],\n",
       "       [0.43883974, 0.56116026],\n",
       "       [0.70353317, 0.29646683],\n",
       "       [0.74158084, 0.25841916],\n",
       "       [0.55638537, 0.44361463],\n",
       "       [0.12863715, 0.87136285],\n",
       "       [0.44018373, 0.55981627],\n",
       "       [0.05865918, 0.94134082],\n",
       "       [0.35288173, 0.64711827],\n",
       "       [0.22164528, 0.77835472],\n",
       "       [0.68963894, 0.31036106],\n",
       "       [0.28704757, 0.71295243],\n",
       "       [0.75587804, 0.24412196],\n",
       "       [0.22164528, 0.77835472],\n",
       "       [0.86836446, 0.13163554],\n",
       "       [0.43712173, 0.56287827],\n",
       "       [0.13590427, 0.86409573],\n",
       "       [0.79924213, 0.20075787],\n",
       "       [0.87055492, 0.12944508],\n",
       "       [0.3803702 , 0.6196298 ],\n",
       "       [0.31385779, 0.68614221],\n",
       "       [0.3803702 , 0.6196298 ],\n",
       "       [0.54889554, 0.45110446],\n",
       "       [0.69423878, 0.30576122],\n",
       "       [0.30971845, 0.69028155],\n",
       "       [0.54072472, 0.45927528],\n",
       "       [0.63537939, 0.36462061],\n",
       "       [0.08524432, 0.91475568],\n",
       "       [0.49046573, 0.50953427]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict_proba(x_test)\n",
    "# first entry in each row is the prob. of output being 0, and second entry is the prob. of output being 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237603ce-2106-4a56-b3d7-4ad5dccf8e2a",
   "metadata": {},
   "source": [
    "### Summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8525b14-53f2-48e5-aaff-7cdccb1e465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefficients = reg.coef_\n",
    "model_intercept = reg.intercept_\n",
    "coefficient_names = np.transpose(input_data_nonscaled.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51e64770-39c4-4bb0-ba94-43e557e04899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.87035055],\n",
       "       [ 0.64757244],\n",
       "       [ 3.00812968],\n",
       "       [ 1.01471336],\n",
       "       [-0.19575089],\n",
       "       [ 0.68355783],\n",
       "       [-0.1918796 ],\n",
       "       [ 0.21331314],\n",
       "       [-0.26278644],\n",
       "       [ 0.38579009],\n",
       "       [-0.32807831]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_coefficients.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d27a6e32-6410-4fab-9e89-2fe5f992232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary = pd.DataFrame(data=coefficient_names,columns=[\"Feature Names\"])\n",
    "model_summary[\"Coefficients\"] = model_coefficients.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b799c8f1-447b-4a64-acc8-42b47cf033c5",
   "metadata": {},
   "source": [
    "#### Add the intercept value to the summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e558f8d5-6e3d-4bf5-8566-08bdc160498a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Names</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.704434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Absence Reason 1</td>\n",
       "      <td>2.870351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absence Reason 2</td>\n",
       "      <td>0.647572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Absence Reason 3</td>\n",
       "      <td>3.008130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absence Reason 4</td>\n",
       "      <td>1.014713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Day of the Week</td>\n",
       "      <td>-0.195751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.683558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.191880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.213313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>-0.262786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Children</td>\n",
       "      <td>0.385790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.328078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature Names  Coefficients\n",
       "0                Intercept     -1.704434\n",
       "1         Absence Reason 1      2.870351\n",
       "2         Absence Reason 2      0.647572\n",
       "3         Absence Reason 3      3.008130\n",
       "4         Absence Reason 4      1.014713\n",
       "5          Day of the Week     -0.195751\n",
       "6   Transportation Expense      0.683558\n",
       "7                      Age     -0.191880\n",
       "8          Body Mass Index      0.213313\n",
       "9                Education     -0.262786\n",
       "10                Children      0.385790\n",
       "11                    Pets     -0.328078"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary.index = model_summary.index + 1\n",
    "model_summary.loc[0] = [\"Intercept\", reg.intercept_[0]]\n",
    "model_summary = model_summary.sort_index()\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7db80e-76a5-42f1-bbd1-dd8db5b9ef48",
   "metadata": {},
   "source": [
    "### Add the change in the odds wr. to features to the summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8852b35a-6f07-45a0-b8a1-6c6560804df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.181875\n",
       "1     17.643202\n",
       "2      1.910896\n",
       "3     20.249491\n",
       "4      2.758573\n",
       "5      0.822217\n",
       "6      1.980913\n",
       "7      0.825406\n",
       "8      1.237772\n",
       "9      0.768906\n",
       "10     1.470776\n",
       "11     0.720307\n",
       "Name: Coefficients, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds_weights = np.exp(model_summary[\"Coefficients\"])\n",
    "odds_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b61f7623-ce12-4280-a59b-d3daea14398c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Names</th>\n",
       "      <th>Weight Towards Odds Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Absence Reason 3</td>\n",
       "      <td>20.249491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Absence Reason 1</td>\n",
       "      <td>17.643202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absence Reason 4</td>\n",
       "      <td>2.758573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>1.980913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absence Reason 2</td>\n",
       "      <td>1.910896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Children</td>\n",
       "      <td>1.470776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>1.237772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.825406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Day of the Week</td>\n",
       "      <td>0.822217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.768906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pets</td>\n",
       "      <td>0.720307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>0.181875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature Names  Weight Towards Odds Ratio\n",
       "3         Absence Reason 3                  20.249491\n",
       "1         Absence Reason 1                  17.643202\n",
       "4         Absence Reason 4                   2.758573\n",
       "6   Transportation Expense                   1.980913\n",
       "2         Absence Reason 2                   1.910896\n",
       "10                Children                   1.470776\n",
       "8          Body Mass Index                   1.237772\n",
       "7                      Age                   0.825406\n",
       "5          Day of the Week                   0.822217\n",
       "9                Education                   0.768906\n",
       "11                    Pets                   0.720307\n",
       "0                Intercept                   0.181875"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds_summary = pd.DataFrame(data=odds_weights.values,columns=[\"Weight Towards Odds Ratio\"])\n",
    "odds_summary[\"Feature Names\"] = model_summary[\"Feature Names\"]\n",
    "odds_summary = odds_summary[[\"Feature Names\", \"Weight Towards Odds Ratio\"]]\n",
    "odds_summary = odds_summary.sort_values([\"Weight Towards Odds Ratio\"],ascending=False)\n",
    "odds_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "602d1a5b-de9a-4e1f-b984-e32730e61f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model\",\"wb\") as file:\n",
    "    pickle.dump(reg, file)\n",
    "\n",
    "with open(\"scaler\",\"wb\") as file:\n",
    "    pickle.dump(absenteeism_scaler, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
